{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import compress\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DICOM = '../MRIs/DICOM'\n",
    "PATH_H5 = '../data/testdata_dicom.h5'\n",
    "PATH_BASELINE = '../data/baseline_data_DWI.csv'\n",
    "IMAGE_DIMENSIONS = (128, 128, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fov(ref_file, image_dims_3d):\n",
    "    ConstPixelSpacing = (float(ref_file.PixelSpacing[0]), float(ref_file.PixelSpacing[1]), float(ref_file.SliceThickness))\n",
    "\n",
    "    x_fov = (image_dims_3d[0]+1)*ConstPixelSpacing[0]\n",
    "    y_fov = (image_dims_3d[1]+1)*ConstPixelSpacing[1]\n",
    "    z_fov = (image_dims_3d[2]+1)*ConstPixelSpacing[2]\n",
    "\n",
    "    return x_fov, y_fov, z_fov\n",
    "\n",
    "def get_pixel_spacing(image_fov, image_dims_3d):\n",
    "\n",
    "    x = np.arange(0.0, image_fov[0], image_fov[0] / image_dims_3d[0])\n",
    "    y = np.arange(0.0, image_fov[1], image_fov[1] / image_dims_3d[1])\n",
    "    z = np.arange(0.0, image_fov[2], image_fov[2] / image_dims_3d[2])\n",
    "\n",
    "    return x, y, z\n",
    "\n",
    "def load_images(file_list):\n",
    "    \n",
    "    ## loads DICOM images from file_list and creates a 3D array with pixel data\n",
    "    \n",
    "    ref_file = pydicom.read_file(file_list[0])\n",
    "    image_dims_3d = (int(ref_file.Rows), int(ref_file.Columns), len(file_list))\n",
    "    # print(\"Original image size: {}\".format(image_dims_3d))\n",
    "\n",
    "    image_fov = get_fov(ref_file, image_dims_3d)\n",
    "    original_spacing = get_pixel_spacing(image_fov, image_dims_3d)\n",
    "    origArray = np.zeros(image_dims_3d, dtype=ref_file.pixel_array.dtype)\n",
    "    origArray.shape\n",
    "\n",
    "    # loop through all the DICOM files\n",
    "    removed = 0\n",
    "    file_list.sort()\n",
    "    for filename in file_list:\n",
    "        # read the file\n",
    "        ds = pydicom.read_file(filename)\n",
    "        # store the raw image data\n",
    "\n",
    "        if(ds.Rows != ref_file.Rows):\n",
    "            removed  += 1\n",
    "            continue\n",
    "\n",
    "        origArray[:, :, file_list.index(filename)] = ds.pixel_array\n",
    "\n",
    "    if(removed != 0):\n",
    "        print('removed {} files for sequence {}'.format(removed, ref_file.SequenceName))\n",
    "\n",
    "    return origArray #, image_fov, original_spacing\n",
    "\n",
    "def normalize_array(array):\n",
    "    min = np.min(array)\n",
    "    max = np.max(array)\n",
    "    normalized = (array - min) / (max - min)\n",
    "    return normalized\n",
    "\n",
    "def scale_array(array, dims):\n",
    "    \n",
    "    ## scales array to IMAGE_DIMENSIONS and normalizes to [0,1]\n",
    "    \n",
    "    scaling_factor = [dims[0]/array.shape[0], dims[1]/array.shape[1], dims[2]/array.shape[2]]\n",
    "    scaledArray = ndimage.zoom(array, scaling_factor)\n",
    "    scaledArray = normalize_array(scaledArray)\n",
    "\n",
    "    # print(\"Scaled image size: {}\".format(dims))\n",
    "    return scaledArray\n",
    "\n",
    "def plot_all_slices(data, orientation = 'axial', vmax = False):\n",
    "    \n",
    "    pixel_spacing = np.arange(0.0, IMAGE_DIMENSIONS[0], 1), \\\n",
    "                    np.arange(0.0, IMAGE_DIMENSIONS[1], 1), \\\n",
    "                    np.arange(0.0, IMAGE_DIMENSIONS[2], 1), \n",
    "    \n",
    "    if orientation == 'axial':\n",
    "        n_slices = min(data.shape[2], 32) # plot maximum 32 slices\n",
    "    else:\n",
    "        n_slices = 32\n",
    "    n_cols = 8\n",
    "    n_rows = math.ceil(n_slices / n_cols)\n",
    "    aspect_ratio = 1\n",
    "    base_size = 2\n",
    "    fig_size = (n_cols*base_size/aspect_ratio, n_rows*base_size)\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "\n",
    "    if orientation == 'axial':\n",
    "        indeces = np.linspace(start=0, stop=data.shape[2]-1, num=n_slices)\n",
    "    else:\n",
    "        indeces = np.linspace(start=0, stop=data.shape[0]-1, num=n_slices)\n",
    "\n",
    "    sp = 1\n",
    "    for index in np.nditer(indeces.astype(int)):\n",
    "        if orientation == 'coronal':\n",
    "            image = np.rot90(data[index, :, ], k = 3)\n",
    "            a = pixel_spacing[0]\n",
    "            b = pixel_spacing[2]\n",
    "        elif orientation == 'sagital':\n",
    "            image = np.rot90(data[:, index, :], k = 3)\n",
    "            a = pixel_spacing[1]\n",
    "            b = pixel_spacing[2]\n",
    "        else:\n",
    "            image = np.rot90(data[:, :, index], k = 2)\n",
    "            a = pixel_spacing[0]\n",
    "            b = pixel_spacing[1]\n",
    "        ax = fig.add_subplot(n_rows, n_cols, sp)\n",
    "        if vmax:\n",
    "            ax.pcolormesh(a, b, image, cmap=\"gray\", vmin = 0, vmax = vmax)\n",
    "        else:\n",
    "            ax.pcolormesh(a, b, image, cmap=\"gray\")\n",
    "        ax.set_aspect('equal', 'box')\n",
    "        ax.set_axis_off()\n",
    "        sp += 1\n",
    "\n",
    "    fig.tight_layout(pad=0.0)\n",
    "    \n",
    "    plt.savefig(\"../data/*re_b1000t.jpg\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Baseline Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data = pd.read_csv(PATH_BASELINE, sep = \" \")\n",
    "baseline_data.p_id = [format(id, '03d') for id in baseline_data.p_id] \n",
    "baseline_data.p_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all paths to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "listFilesDICOM = []\n",
    "\n",
    "for paths, dirnames, filenames in os.walk(PATH_DICOM, topdown = True):\n",
    "    for file in filenames:\n",
    "        if file != 'DICOMDIR' and file[-2:] != 'h5':\n",
    "            listFilesDICOM.append(os.path.join(paths,file))\n",
    "\n",
    "data_info = pd.DataFrame()\n",
    "data_info['patient'] = pd.Series()\n",
    "data_info['sequence'] = pd.Series()\n",
    "data_info['description'] = pd.Series()thundthun\n",
    "data_info['aquisition_time'] = pd.Series()\n",
    "data_info['rows'] = pd.Series()\n",
    "data_info['columns'] = pd.Series()\n",
    "data_info['filepath'] = pd.Series()\n",
    "\n",
    "for index, file in enumerate(listFilesDICOM):\n",
    "    DICOM_file = pydicom.read_file(file)\n",
    "    data_info.loc[index, 'patient'] = file[14:17]\n",
    "    data_info.loc[index, 'sequence'] = DICOM_file.SequenceName ## 0018 0024\n",
    "    data_info.loc[index, 'description'] = DICOM_file.SeriesDescription ## 0008 103e\n",
    "    data_info.loc[index, 'series_number'] = DICOM_file.SeriesNumber ## 0020 0011\n",
    "    data_info.loc[index, 'aquisition_time'] = DICOM_file.AcquisitionTime ## 0008 0032\n",
    "    data_info.loc[index, 'instance_uid'] = DICOM_file.SOPInstanceUID   ## 0008 0018 --> one per image\n",
    "    data_info.loc[index, 'reference_study'] = DICOM_file.ReferencedStudySequence[0].ReferencedSOPInstanceUID  ## 0008 1110 --> one per patient\n",
    "    # data_info.loc[index, 'creation_time'] = DICOM_file.InstanceCreationTime ## 0008 0013 --> not always present\n",
    "    data_info.loc[index, 'rows'] = DICOM_file.Rows ## 0028 0010\n",
    "    data_info.loc[index, 'columns'] = DICOM_file.Columns ## 0028 0011\n",
    "    data_info.loc[index, 'filepath'] = file\n",
    "    # TODO: add pixel spacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICOM header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listFilesDICOM[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_file = pydicom.read_file(listFilesDICOM[0])\n",
    "# ref_file\n",
    "# ref_file.ReferencedStudySequence[0].ReferencedSOPInstanceUID  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import DICOM images to h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data.p_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_patient = True\n",
    "os.remove(PATH_H5)\n",
    "with h5py.File(PATH_H5, 'a') as f:\n",
    "    for patient_number in set(data_info.patient):\n",
    "        \n",
    "        print('loading sequence for patient {}'.format(patient_number))\n",
    "        if patient_number not in list(baseline_data.p_id):\n",
    "            print('patient {} has no baseline values. Sequence will not be loaded. \\n'.format(patient_number))\n",
    "            continue\n",
    "\n",
    "        IMAGE_NAME = []\n",
    "        X = []\n",
    "        \n",
    "        ## load baseline values\n",
    "        PATIENT_NB =  [patient_number]\n",
    "        Y = baseline_data.stroke.loc[baseline_data.p_id == patient_number].values\n",
    "        \n",
    "        ## copy patient specific filepaths\n",
    "        patient_data = data_info[data_info.patient == patient_number].copy()\n",
    "        \n",
    "        ## check if patient has a b1000t sequence\n",
    "        in_set = []\n",
    "        for i in set(patient_data.sequence):\n",
    "            in_set.append('b1000t' in i)\n",
    "        \n",
    "        ## if patient has no or more than one b1000t sequence: choose sequence by hand\n",
    "        if sum(in_set) != 1:\n",
    "            ## --> load images in amide, choose image by name\n",
    "            print('which image should be loaded?')\n",
    "            for index, image in enumerate(set(patient_data.description)):\n",
    "                print('{} - {}'.format(index, image))\n",
    "            choice = input('>')\n",
    "            chosen_sequence = list(set(patient_data.description))[int(choice)]\n",
    "            \n",
    "            print('{} {} \\n'.format(' '.ljust(15), chosen_sequence))\n",
    "            file_list = list(patient_data.filepath[patient_data.description == chosen_sequence])\n",
    "            raw_3d_image = load_images(file_list)\n",
    "            scaled_3d_image = scale_array(raw_3d_image, IMAGE_DIMENSIONS)\n",
    "\n",
    "\n",
    "            IMAGE_NAME.append(chosen_sequence)\n",
    "            X.append(scaled_3d_image)\n",
    "            \n",
    "        ## patient has a b1000t sequence: choose sequence automatically\n",
    "        else:\n",
    "        \n",
    "            for sequence_type in set(patient_data.sequence):\n",
    "            \n",
    "                if 'b1000t' in sequence_type:\n",
    "                \n",
    "                    print('{} {} \\n'.format(sequence_type.ljust(15), \\\n",
    "                                    set(patient_data.description[patient_data.sequence == sequence_type])))\n",
    "                    file_list = list(patient_data.filepath[patient_data.sequence == sequence_type])\n",
    "                    raw_3d_image = load_images(file_list)\n",
    "                    scaled_3d_image = scale_array(raw_3d_image, IMAGE_DIMENSIONS)\n",
    "\n",
    "#                     PATIENT_NB.append(patient_number)\n",
    "                    IMAGE_NAME.append(sequence_type)\n",
    "                    X.append(scaled_3d_image)\n",
    "            \n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "        PATIENT_NB = np.string_(PATIENT_NB)\n",
    "        IMAGE_NAME = np.string_(IMAGE_NAME)\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        \n",
    "        ## write to h5py sequentially\n",
    "        if first_patient: ## initialize dataset\n",
    "            f.create_dataset('X', data = X, maxshape = (None, 128, 128, 128), chunks = True)\n",
    "            f.create_dataset('Y', data = Y, maxshape = (None,), chunks = True)\n",
    "            f.create_dataset('PATIENT_NB', data = PATIENT_NB, maxshape = (None,), chunks = True)\n",
    "            f.create_dataset('IMAGE_NAME', data = IMAGE_NAME, maxshape = (None,), chunks = True)\n",
    "            first_patient = False\n",
    "            \n",
    "        else: ## append dataset\n",
    "            f['X'].resize((f['X'].shape[0] + X.shape[0]), axis = 0)\n",
    "            f['X'][-X.shape[0]:, :, :, :] = X\n",
    "            f['Y'].resize((f['Y'].shape[0] + Y.shape[0]), axis = 0)\n",
    "            f['Y'][-Y.shape[0]:] = Y\n",
    "            f['PATIENT_NB'].resize((f['PATIENT_NB'].shape[0] + PATIENT_NB.shape[0]), axis = 0)\n",
    "            f['PATIENT_NB'][-PATIENT_NB.shape[0]:] = PATIENT_NB\n",
    "            f['IMAGE_NAME'].resize((f['IMAGE_NAME'].shape[0] + IMAGE_NAME.shape[0]), axis = 0)\n",
    "            f['IMAGE_NAME'][-IMAGE_NAME.shape[0]:] = IMAGE_NAME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data_info['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set(data_info['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some Patients have the same description for two differnet sequences\n",
    "- Sequence Types are unique (every sequence has a different name)\n",
    "- But: Patient 4 lacks all Sequence Types\n",
    "- Patient 8 has different names for sequence types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = h5py.File(PATH_H5, 'r')\n",
    "patients = [p.decode() for p in dd['PATIENT_NB']]\n",
    "patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_h5(patient_nb):\n",
    "    dd = h5py.File(PATH_H5, 'r')\n",
    "    patients = [p.decode() for p in dd['PATIENT_NB']]\n",
    "\n",
    "    mri = np.array(dd['X'])[patients.index(patient_nb), :, :, :]\n",
    "    return mri.reshape(IMAGE_DIMENSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mri_sequence = load_from_h5(patient_nb = '001')\n",
    "plot_all_slices(mri_sequence, 'axial', vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_sequence = load_from_h5(patient_nb = '06')\n",
    "plot_all_slices(mri_sequence, 'axial', vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_sequence = load_from_h5(patient_nb = '04')\n",
    "plot_all_slices(mri_sequence, 'axial', vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
